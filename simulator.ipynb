{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"simulator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/jimjoseph51000/fpl-simulator/blob/main/simulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4DYoKDj_gft","executionInfo":{"status":"ok","timestamp":1638333900598,"user_tz":300,"elapsed":16875,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}},"outputId":"809dbcbe-8226-4b9a-a758-7d2b5c06cfd3"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zenpKZI2_gf1","executionInfo":{"status":"ok","timestamp":1638333900871,"user_tz":300,"elapsed":286,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}},"outputId":"13ab0591-6c04-4c45-9217-b96e4821190c"},"source":["% cd /gdrive/MyDrive/CSE_519_DSF/gitcode/fpl-simulator-main/"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/CSE_519_DSF/gitcode/fpl-simulator-main\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kISPLLjp_qc4","executionInfo":{"status":"ok","timestamp":1638333901110,"user_tz":300,"elapsed":254,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}},"outputId":"6128029d-d36a-494e-f4a1-ae31e31dfaf6"},"source":["% ls"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["'CSE_519_DSF_Proposal___Fantasy_Premier_League (1).pdf'   player_types.csv\n","'CSE_519___FPL_Progress_Report (1).pdf'                  \u001b[0m\u001b[01;34m'Progress Report'\u001b[0m/\n"," LICENSE                                                  \u001b[01;34m__pycache__\u001b[0m/\n"," model.py                                                 README.md\n"," \u001b[01;34mmodels\u001b[0m/                                                  readme_plot.png\n"," \u001b[01;34mPlayer_Cost_Weekwise\u001b[0m/                                   'Sanity Checker.ipynb'\n","'Player Embedding.ipynb'                                  scout.py\n","'Player Profiles.ipynb'                                   simulator.ipynb\n"," \u001b[01;34mPlayer_Rankings\u001b[0m/                                         simulator.py\n"," \u001b[01;34mPlayers_Weekwise\u001b[0m/\n"]}]},{"cell_type":"code","metadata":{"id":"miP5s1WTKT1X","executionInfo":{"status":"ok","timestamp":1638333907933,"user_tz":300,"elapsed":6828,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","from matplotlib import pyplot as plt\n","\n","from simulator import *\n","from model import *\n","from scout import * \n","# from util import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gBJUdtVvdAWI","executionInfo":{"status":"ok","timestamp":1638334264282,"user_tz":300,"elapsed":164,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}}},"source":["\n","import math\n","import glob\n","import io\n","import base64\n","import time\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","from collections import namedtuple\n","from itertools import count\n","\n","# Colab comes with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.autograd as autograd\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import datetime\n","import copy\n","\n","def random_action():\n","  idx = np.random.randint(N_actions)\n","  return possible_actions[idx], idx\n","\n","def epsilon_greedy_action(env, state, model, epsilon, t):\n","\n","  state = np.array(state) # (N_states,)\n","  assert(state.shape == (620,))\n","  assert(state.ndim == 1)\n","  # bp()\n","  week_vector = np.zeros(current_week)\n","  week_vector[t] = 1.0\n","  state = np.append(state, week_vector) # (630,)\n","  # we are gonna evaluate over all the different set of actions\n","  # print(possible_actions.shape) # (5,11)\n","  input = np.hstack((np.broadcast_to(state,(possible_actions.shape[0], state.shape[0])), possible_actions)) # (N_A,N_S+N_A)\n","  # print(input.shape)\n","  assert(input.shape == (N_actions, possible_actions.shape[1] + N_states + current_week)) # we are adding in the week vector too for now\n","\n","  X = torch.from_numpy(input).float().cuda()\n","  model.eval()\n","  Y = model(X)\n","  assert(Y.shape == (N_actions,1))\n","  Y = Y.detach().cpu().numpy()\n","  best_idx = np.argmax(Y.reshape(-1))\n","\n","  # you dont get to choose the best action. have soft probabilities based on exploration epsilon\n","  selection_prob_arr = np.zeros(N_actions, dtype=np.float)\n","  selection_prob_arr[:] = epsilon / N_actions\n","  selection_prob_arr[best_idx] = (epsilon / N_actions) + (1 - epsilon)\n","  # bp()\n","  assert(selection_prob_arr.sum().round() == 1.0)\n","  idx = np.random.choice(N_actions,1,replace=False, p = selection_prob_arr)\n","  # assert(idx.shape == (1,))\n","  model.train()\n","  # bp()\n","  # env.action_space.sample()\n","  return possible_actions[idx[0]], idx[0]\n","\n","def calculate_episode_return(episode, gamma):\n","  episode = np.array(episode)\n","  assert(episode.ndim == 2)\n","  assert(episode.shape[0] == current_week)\n","  states_array = episode[:,0]\n","  # actions_array = episode[:,1]\n","  rewards_array = episode[:,2]\n","  # gamma_array = [gamma**i for i in range(episode.shape[0])]\n","  # Gt = rt + gamma * Gt\\+1.\n","  # bp()\n","  G = np.array([0 for i in range(states_array.shape[0])], dtype = np.float)\n","  for i in range(G.shape[0]-1,-1,-1):\n","    # temp = G[i+1]\n","    if i == G.shape[0] - 1:\n","      temp = 0\n","    else:\n","      temp = G[i+1]\n","    G[i] = rewards_array[i] + gamma * temp\n","  # bp()\n","  # print(G)\n","  # assert(G[-1] == 1.0)\n","  return G\n","\n","\n","def update_Q_value(G, episode, model, optimizer):\n","  episode = np.array(episode)\n","  model = model.cuda()\n","  model.train()\n","  optimizer.zero_grad()\n","  loss_criterion = nn.MSELoss()\n","  # bp()\n","  action_arr = possible_actions[np.array(episode[:,1], np.int),:] #(num_weeks,N_actions)\n","  state_arr = np.array([i.tolist() for i in episode[:,0]], np.float) #(num_weeks,N_states)\n"," \n","  assert(state_arr.shape[0] == action_arr.shape[0])\n","  week_vector = np.eye(current_week) # (num_weeks,num_weeks)\n","  # print('update',state_arr.shape, week_vector.shape)\n","  state_arr = np.hstack((state_arr, week_vector)) # (num_weeks, N_states + num_weeks)\n","  X = torch.from_numpy(np.hstack((state_arr, action_arr))).cuda().float() #(num_weeks, N_states + num_weeks + N_actions) \n","  # print(X.shape)\n","  Y = torch.from_numpy(G[:,np.newaxis]).float().cuda() # (B,1)\n","  # old_mean = Y.mean()\n","  # old_std = Y.std()\n","  # Y = (Y - old_mean) / old_std \n","  # bp()\n","  output = model(X)\n","  # print('output {}, Y {}'.format(output.mean(),Y.mean()))\n","  assert(output.shape == Y.shape)\n","  loss = loss_criterion(output,Y)\n","  loss.backward()\n","  optimizer.step()\n","  assert(loss.grad_fn != None)\n","  model.eval()\n","  return loss.detach().cpu().numpy(), output.detach().cpu().numpy(), Y.detach().cpu().numpy()"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8uQPJIgw0GG"},"source":["### Model Training\n"]},{"cell_type":"code","metadata":{"id":"TqFx0iCHv2kN","colab":{"base_uri":"https://localhost:8080/","height":849},"executionInfo":{"status":"error","timestamp":1638334455966,"user_tz":300,"elapsed":148105,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}},"outputId":"6a21f390-7824-4e3c-80fe-5598b44e513f"},"source":["\"\"\"\n","Training the model for MC Control for FPL environment\n","\"\"\"\n","# % rm /content/video/*.*\n","\n","print('Training the model for MC Control for FPL environment')\n","\n","save_path = './models/'\n","if not os.path.exists(save_path):\n","  os.makedirs(save_path)\n","print('save path :{}'.format(save_path))\n","\n","np.random.seed(11)\n","random.seed(11)\n","torch.manual_seed(11)\n","torch.backends.cudnn.enabled = False\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.cuda.manual_seed(11)\n","torch.cuda.manual_seed_all(11)\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","torch.cuda.device(DEVICE)\n","\n","epsilon = 0.2\n","epsilon_decay = 0.99\n","epsilon_min = 0.1\n","gamma = 1.0\n","# possible_actions = np.array([[1,0,0,0,0],[0,1]]) # left or right discretized (2,2)\n","\n","\n","\n","# -----------------------------------------------\n","# TODO : try adjusting these params\n","n_episode = 10000     # number of episodes\n","max_steps = 1000  # maximum steps for each episode\n","lr = 1e-3\n","epsilon_iter_delta = 200 # this needs to be high . need more exploration \n","\n","fpl_manager_id = '2757'\n","current_week = 10\n","env = FPLSimulator(current_week, fpl_manager_id, req_cols=['stats.ict_index','element_type'])\n","min_balance = 10\n","current_balance = env.balance\n","K = 15\n","# scout = Scout(env, 0, min_balance, env.balance, K)\n","\n","N_actions = len(profiles)\n","N_states = env.all_player_ids.shape[0] # (620,)\n","possible_actions = np.array([d['prob_dist'] for d in profiles])\n","\n","network = RecruiterNetwork(N_states + current_week, possible_actions.shape[1])\n","network = network.cuda()\n","optimizer = optim.Adam(network.parameters(), lr=lr)\n","network.train()\n","\n","\n","\n","# possible_actions = np.eye(N_actions)\n","\n","\n","for i_episode in range(n_episode):\n","  observation = env.reset() # get the state\n","  episode = []\n","  G_all = []\n","\n","  if i_episode % epsilon_iter_delta == 0:\n","    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n","\n","  # this creates 'W' different transfers, like one every week\n","  # method of training : 1. have a \n","  \n","  for t in range(current_week):\n","    scout = Scout(env, t, min_balance, env.balance, K)\n","\n","    s = observation\n","    a, action_idx = epsilon_greedy_action(env, s, network, epsilon, t)\n","    # a, action_idx = random_action() \n","    observation, r, done = env.step(action_idx, t, scout)\n","    # s_prime = observation\n","    episode.append([s,action_idx,r])\n","    # print('episode {}, game week {}'.format(i_episode, t))\n","    if done:\n","      break\n","  # more_episodes = generate_episodes(env, episode)\n","\n","  G_all = calculate_episode_return(episode,gamma)\n","  loss,out,gt = update_Q_value(G_all, episode, network, optimizer)\n","  if i_episode % 100 == 0:\n","     print('{} # {}, epsilon {},return {}, out {}, Y {} loss : {}'.format(datetime.datetime.now(), i_episode , epsilon, G_all[0], out.mean(), gt.mean(), loss))\n","  # break\n","\n","\n","print('Done !')\n","print('saved model')\n","torch.save(network.state_dict(), os.path.join(save_path,'recruiter_mgr_id_{}.pth'.format(fpl_manager_id)))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Training the model for MC Control for FPL environment\n","save path :./models/\n","(620,) (620, 10) (620, 10) (2, 620, 10)\n","cumsum of per_week_total_points:  [ 80. 166. 238. 297. 355. 401. 436. 484. 540. 588.]\n","(15, 10) (15, 10) (15, 10) (2, 15, 10)\n","2021-12-01 04:51:49.142388 # 0, epsilon 0.495,return -4.0, out -0.07043598592281342, Y -2.200000047683716 loss : 6.89596700668335\n","2021-12-01 04:51:56.138292 # 100, epsilon 0.495,return -2.0, out -0.9195262789726257, Y -1.600000023841858 loss : 0.7216588258743286\n","2021-12-01 04:52:03.068090 # 200, epsilon 0.49005,return -2.0, out -0.8611918687820435, Y -1.2000000476837158 loss : 0.2681889533996582\n","2021-12-01 04:52:09.938022 # 300, epsilon 0.49005,return 0.0, out -0.7002339363098145, Y 0.0 loss : 0.7159218788146973\n","2021-12-01 04:52:16.859820 # 400, epsilon 0.48514949999999996,return -3.0, out -1.3210338354110718, Y -1.7000000476837158 loss : 0.38828524947166443\n","2021-12-01 04:52:23.952096 # 500, epsilon 0.48514949999999996,return -2.0, out -0.7611302733421326, Y -1.399999976158142 loss : 0.6119734048843384\n","2021-12-01 04:52:30.738306 # 600, epsilon 0.480298005,return -5.0, out -1.1744301319122314, Y -2.799999952316284 loss : 4.745878219604492\n","2021-12-01 04:52:37.567425 # 700, epsilon 0.480298005,return 0.0, out -0.9561718702316284, Y 0.0 loss : 1.3780030012130737\n","2021-12-01 04:52:44.538242 # 800, epsilon 0.47549502494999996,return 0.0, out -0.7687815427780151, Y 0.0 loss : 0.8151969313621521\n","2021-12-01 04:52:51.349405 # 900, epsilon 0.47549502494999996,return -1.0, out -0.9982537031173706, Y -0.6000000238418579 loss : 0.21622887253761292\n","2021-12-01 04:52:58.263739 # 1000, epsilon 0.47074007470049994,return 0.0, out -0.6579560041427612, Y 0.0 loss : 0.6215943694114685\n","2021-12-01 04:53:05.322304 # 1100, epsilon 0.47074007470049994,return 0.0, out -1.015824317932129, Y 0.0 loss : 1.409902811050415\n","2021-12-01 04:53:12.442375 # 1200, epsilon 0.46603267395349496,return -3.0, out -0.9708613157272339, Y -2.0 loss : 1.4350003004074097\n","2021-12-01 04:53:19.328282 # 1300, epsilon 0.46603267395349496,return 0.0, out -1.2053656578063965, Y 0.0 loss : 2.242704153060913\n","2021-12-01 04:53:26.224288 # 1400, epsilon 0.46137234721396,return -1.0, out -0.7283428907394409, Y -0.20000000298023224 loss : 0.4189917743206024\n","2021-12-01 04:53:33.078038 # 1500, epsilon 0.46137234721396,return 0.0, out -0.6576616764068604, Y 0.0 loss : 0.6775244474411011\n","2021-12-01 04:53:40.036792 # 1600, epsilon 0.45675862374182036,return -1.0, out -0.7619208693504333, Y -0.30000001192092896 loss : 0.2925437390804291\n","2021-12-01 04:53:47.003432 # 1700, epsilon 0.45675862374182036,return -1.0, out -0.8296109437942505, Y -1.0 loss : 0.1822419911623001\n","2021-12-01 04:53:54.043146 # 1800, epsilon 0.45219103750440215,return -4.0, out -1.1116433143615723, Y -2.5 loss : 2.4872231483459473\n","2021-12-01 04:54:00.986404 # 1900, epsilon 0.45219103750440215,return -2.0, out -0.9531404376029968, Y -0.699999988079071 loss : 0.3408336639404297\n","2021-12-01 04:54:07.864667 # 2000, epsilon 0.44766912712935814,return -2.0, out -1.0543127059936523, Y -1.5 loss : 0.4582434594631195\n","2021-12-01 04:54:15.367506 # 2100, epsilon 0.44766912712935814,return -2.0, out -0.8394050598144531, Y -1.600000023841858 loss : 0.8030252456665039\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-cd9913db07e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_greedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# a, action_idx = random_action()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m# s_prime = observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mepisode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/gdrive/MyDrive/CSE_519_DSF/gitcode/fpl-simulator-main/simulator.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_idx, week_idx, scout)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfers_in_episode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_transfer_ins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# IMP : this step is needed but change this to the actual transfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_player_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_player_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_player_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_transfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_transfer_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_player_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_one_hot_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_player_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# IMP : this step is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/gdrive/MyDrive/CSE_519_DSF/gitcode/fpl-simulator-main/simulator.py\u001b[0m in \u001b[0;36mdo_transfer\u001b[0;34m(self, transfer_ins, actual_players_ids)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;31m# 6. we need to have the points and the cost matrix for the new team too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m     \u001b[0mnew_team_player_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_player_info_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_player_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_team_player_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0mnew_team_player_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_player_info_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_player_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_team_player_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/gdrive/MyDrive/CSE_519_DSF/gitcode/fpl-simulator-main/simulator.py\u001b[0m in \u001b[0;36mget_player_info_matrix\u001b[0;34m(self, all_player_info, actual_players_ids)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mact_P_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_players_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_players_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_player_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# (15, 10, 620)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mall_P_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_player_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_players_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_player_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;31m# (15, 10, 620)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mmatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_P_reshaped\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall_P_reshaped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this should have all the matches, lets do an assertion check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactual_players_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# just see how hte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"UI7dIIMMxhWk","executionInfo":{"status":"aborted","timestamp":1638333924195,"user_tz":300,"elapsed":21,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}}},"source":["test = np.eye(5)\n","assert(np.all(test > 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NSJpx4jhwZa7","executionInfo":{"status":"aborted","timestamp":1638333924197,"user_tz":300,"elapsed":23,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}}},"source":["np.array(episode)[:,2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNOW_EqKsa53","executionInfo":{"status":"aborted","timestamp":1638333924198,"user_tz":300,"elapsed":23,"user":{"displayName":"Jimmy Joseph","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16028997389143775922"}}},"source":[""],"execution_count":null,"outputs":[]}]}